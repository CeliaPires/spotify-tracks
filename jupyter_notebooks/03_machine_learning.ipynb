{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4504a1",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7030a8ff",
   "metadata": {},
   "source": [
    "Aim:\n",
    "Task 1: Genre Classification\n",
    "Predict the track_genre from audio features (supervised ML)\n",
    "Task 2: Song Recommendation\n",
    "Recommend similar songs based on audio similarity (unsupervised ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9991017",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac0733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# ML models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Recommendation\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffce00b",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec383604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/03_spotify_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e07d5",
   "metadata": {},
   "source": [
    "Inspecting data types in 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0ff8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popularity            int64\n",
       "duration_ms           int64\n",
       "explicit               bool\n",
       "danceability        float64\n",
       "energy              float64\n",
       "key                   int64\n",
       "loudness            float64\n",
       "mode                  int64\n",
       "speechiness         float64\n",
       "acousticness        float64\n",
       "instrumentalness    float64\n",
       "liveness            float64\n",
       "valence             float64\n",
       "tempo               float64\n",
       "time_signature        int64\n",
       "popularity_bin       object\n",
       "danceability_bin     object\n",
       "energy_bin           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d57e5e",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79777bb6",
   "metadata": {},
   "source": [
    "- X will contain only the raw numeric features (e.g., popularity, danceability, energy, etc.)\n",
    "- y will contain encoded genre labels (e.g., 0 = \"pop\", 1 = \"rock\", ...)\n",
    "- X_scaled is the input to feed into your ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf346987",
   "metadata": {},
   "source": [
    "Step 3.1: Select features (X) and drop irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 'artists', 'album_name', 'track_name': Text data (requires NLP to be useful)\n",
    "# - 'track_genre': This is the target variable\n",
    "# - 'popularity_bin', 'danceability_bin', 'energy_bin': Manually created bins (categorical, not useful for raw ML modeling)\n",
    "\n",
    "X = df.drop(columns=[\n",
    "    'artists', 'album_name', 'track_name',\n",
    "    'track_genre',\n",
    "    'popularity_bin', 'danceability_bin', 'energy_bin'  # drop derived text bins\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191d934",
   "metadata": {},
   "source": [
    "Step 3.2: Prepare target variable (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2273ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the track genre as numbers (ML models need numeric targets)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['track_genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919da048",
   "metadata": {},
   "source": [
    "Step 3.3: Normalise Numeric Feature Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features ensures all numerical columns have similar ranges. This is especially important for algorithms sensitive to magnitude\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651f725",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a62507",
   "metadata": {},
   "source": [
    "## Step 5: Train Classifier (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0afabfe",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode labels for readability\n",
    "y_test_labels = le.inverse_transform(y_test)\n",
    "y_pred_labels = le.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels, labels=le.classes_)\n",
    "sns.heatmap(cm, xticklabels=le.classes_, yticklabels=le.classes_, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97849d",
   "metadata": {},
   "source": [
    "## Step 7: Song Recommendation System (Using Audio Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a846459",
   "metadata": {},
   "source": [
    "We'll use K-Nearest Neighbors to find songs that are similar based on features like danceability, energy, valence, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same features and scaling\n",
    "audio_features = scaler.fit_transform(X)\n",
    "\n",
    "# Fit KNN model\n",
    "knn = NearestNeighbors(n_neighbors=6, metric='cosine')  # 6 so first result is itself + 5 recommendations\n",
    "knn.fit(audio_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4bd7b",
   "metadata": {},
   "source": [
    "Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f15a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_song(song_index, df_original, model, features_scaled):\n",
    "    distances, indices = model.kneighbors([features_scaled[song_index]])\n",
    "    print(f\"\\nSelected Song: {df_original.iloc[song_index]['track_name']} - {df_original.iloc[song_index]['artists']}\\n\")\n",
    "    print(\"Recommended Songs:\\n\")\n",
    "    for idx in indices[0][1:]:  # skip first (it's the input song itself)\n",
    "        row = df_original.iloc[idx]\n",
    "        print(f\"{row['track_name']} - {row['artists']} (Genre: {row['track_genre']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0708554",
   "metadata": {},
   "outputs": [],
   "source": [
    "Examlple song index to recommend \n",
    "# Recommend songs similar to the 10th track in the dataset\n",
    "recommend_song(10, df, knn, audio_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
